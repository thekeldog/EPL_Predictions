{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Match Outcomes from English Premier League Data 2016-2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Basic imports'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "''' Machine learning imports'''\n",
    "# Feature Importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data from R\n",
    "   \n",
    "clean_train = pd.read_csv('/Users/Kellen/Desktop/CSUMB SCHTUFF/CST463/EPL_Predictions/CleanPLTrain')\n",
    "\n",
    "col_names = list(clean_train)\n",
    "\n",
    "train_y = clean_train['FTR']\n",
    "\n",
    "clean_train = clean_train.drop(['FTR','Upset',\n",
    "                                'PredictedOutcome',\n",
    "                                'UpsetNumeric'], axis=1\n",
    "                              )\n",
    "\n",
    "clean_test = pd.read_csv('/Users/Kellen/Desktop/CSUMB SCHTUFF/CST463/EPL_Predictions/CleanPLTest')\n",
    "\n",
    "test_y = clean_test['FTR']\n",
    "\n",
    "clean_test = clean_test.drop(['FTR', 'Upset',\n",
    "                              'PredictedOutcome',\n",
    "                              'UpsetNumeric'],axis=1\n",
    "                            )\n",
    "\n",
    "clean_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pre-Processing/Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train_x = scaler.fit_transform(X=clean_train,y=None)\n",
    "\n",
    "scaled_test_x = scaler.fit_transform(clean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(scaled_train_x, train_y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = importances.index()\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X.shape[1]), indices)\n",
    "# plt.xlim([-1, X.shape[1]])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some quick predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Blind Prediction Rate: '+ str(round( (sum(train_y == 'H')/len(train_y)) , 2) ) )\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "rf.fit(scaled_train_x,train_y)\n",
    "rf.score(scaled_test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(scaled_train_x,train_y)\n",
    "neigh.score(scaled_test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier()\n",
    "n_estimators = np.arange(1,20)\n",
    "depth = np.arange(1,10)\n",
    "learning_rates = [0.01,0.1,1]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators , 'max_depth' : depth, 'learning_rate':learning_rates}\n",
    "\n",
    "grid1 = GridSearchCV(gbrt, param_grid = param_grid, cv = 5)\n",
    "grid1.fit(scaled_train_x,train_y.ravel())\n",
    "\n",
    "print(\"Best Accuracy: \",grid1.best_score_*100)\n",
    "print(\"Best params: \", grid1.best_params_)\n",
    "\n",
    "grid1.score(scaled_test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(scaled_train_x,train_y)\n",
    "nb.score(scaled_test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
